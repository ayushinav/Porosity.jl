<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Interface · MT.jl</title><meta name="title" content="Interface · MT.jl"/><meta property="og:title" content="Interface · MT.jl"/><meta property="twitter:title" content="Interface · MT.jl"/><meta name="description" content="Documentation for MT.jl."/><meta property="og:description" content="Documentation for MT.jl."/><meta property="twitter:description" content="Documentation for MT.jl."/><meta property="og:url" content="https://ayushinav.github.io/MT/probabilistic_inverse.html"/><meta property="twitter:url" content="https://ayushinav.github.io/MT/probabilistic_inverse.html"/><link rel="canonical" href="https://ayushinav.github.io/MT/probabilistic_inverse.html"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">MT.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Home</a></li><li><a class="tocitem" href="model.html">model</a></li><li><a class="tocitem" href="forward.html">forward</a></li><li><a class="tocitem" href="deterministic_inverse.html">Deterministic Inverse</a></li><li><a class="tocitem" href="domain_transformation.html">domain transformation</a></li><li><a class="tocitem" href="interface_guide.html">interface guide</a></li><li><span class="tocitem">Probabilistic inverse</span><ul><li class="is-active"><a class="tocitem" href="probabilistic_inverse.html">Interface</a><ul class="internal"><li><a class="tocitem" href="#Constructing-distributions-to-sample-from"><span>Constructing distributions to sample from</span></a></li><li><a class="tocitem" href="#Inference"><span>Inference</span></a></li><li><a class="tocitem" href="#Copy-Pasteable-code"><span>Copy-Pasteable code</span></a></li></ul></li><li><a class="tocitem" href="tutorials/fixed_discretization.html">MCMC with fixed discretization</a></li><li><a class="tocitem" href="tutorials/variable_discretization.html">MCMC with variable discretization</a></li><li><a class="tocitem" href="tutorials/rto.html">RTO-TKO</a></li><li><a class="tocitem" href="rock_physics.html">rock physics</a></li></ul></li><li><a class="tocitem" href="vizualization.html">Vizualization</a></li><li><a class="tocitem" href="api.html">API</a></li><li><a class="tocitem" href="working_with_mtpy.html">mtpy tutorial</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Probabilistic inverse</a></li><li class="is-active"><a href="probabilistic_inverse.html">Interface</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="probabilistic_inverse.html">Interface</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ayushinav/MT" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Probabilistic-inversion"><a class="docs-heading-anchor" href="#Probabilistic-inversion">Probabilistic inversion</a><a id="Probabilistic-inversion-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilistic-inversion" title="Permalink"></a></h1><p>Performing stochastic inversion involves forming the model prior space, defining the likelihood and then getting samples from the posterior space. </p><h2 id="Constructing-distributions-to-sample-from"><a class="docs-heading-anchor" href="#Constructing-distributions-to-sample-from">Constructing distributions to sample from</a><a id="Constructing-distributions-to-sample-from-1"></a><a class="docs-heading-anchor-permalink" href="#Constructing-distributions-to-sample-from" title="Permalink"></a></h2><h3 id="Model-distribution-(*a-priori*-information)"><a class="docs-heading-anchor" href="#Model-distribution-(*a-priori*-information)">Model distribution (<em>a priori</em> information)</a><a id="Model-distribution-(*a-priori*-information)-1"></a><a class="docs-heading-anchor-permalink" href="#Model-distribution-(*a-priori*-information)" title="Permalink"></a></h3><p>Before beginning to talk about how to construct the <em>a priori</em> distribution, it is important to understand that the model here refers to the discretization space as well as the values of physical properties. For eg, for electrical methods, the model space will consist of the electrical resistivity as well as the grid sizes represented by those. This is primarily useful in 1D, but can have its own consequences.</p><p>For most applications, however, we fix the node points. We follow a 1D MT example to show the framework. For now, we begin by choosing a very broad prior for all the <code>n</code> layers. A model distribution can be constructed using <code>MTModelDistribution(...)</code>. This has the same structure as <code>MTModel</code>, that is, the first parameter denotes the prior for electrical conductivities, while the second is for the layer thicknesses <code>h</code>. If you do not want to infer on <code>h</code>, just pass it as a simple vector, as is also demonstrated in the following case:</p><pre><code class="language-julia hljs">n = 50 # number of layers
h = fill(20., n-1) # making the discretization

# prior space with fixed model discretization
modelD = MTModelDistribution(
    Product(
    [Uniform(-1, 5) for i in 1:n]
    ),
    vec(h) # fixed h
);</code></pre><p>Some of the things to understand here are :</p><ul><li><code>Product(...)</code> is a <code>Distributions.jl</code> function that joins a series of multivariate/univariate samples, here <code>Uniform(-1,5)</code>. Thus, <code>Product([Uniform(-1, 5) for in 1:n])</code> makes a sampler that will output an <code>n</code>-length vector, with each element sampled from <code>Uniform(-1,5)</code>. Here, we use a uniform prior, but one can choose any prior. The only thing to keep in mind is that the prior can be sampled, that is, <code>rand(modelD.m)</code> returns a vector of appropriate length. Another eg., would be <code>MultivariateNormal(μ, Σ)</code>.</li><li>To also sample <code>h</code>, pass another multivariate distribution that outputs <code>n-1</code> length vector. Again using a uniform, independent prior, we&#39;ll have:</li></ul><pre><code class="language-julia hljs">
# prior space with variable model discretization
modelD = MTModelDistribution(
    Product(
        [Uniform(-1, 5) for i in 1:n]
    ),
    Product(
        [Uniform(15, 25) for i in 1:(n-1)]
    )
);
</code></pre><p>This has its own consequences on the results and one needs to be mindful of that while interpreting the results.</p><h3 id="Response-distribution-(*likelihood*)"><a class="docs-heading-anchor" href="#Response-distribution-(*likelihood*)">Response distribution (<em>likelihood</em>)</a><a id="Response-distribution-(*likelihood*)-1"></a><a class="docs-heading-anchor-permalink" href="#Response-distribution-(*likelihood*)" title="Permalink"></a></h3><p>A likelihood is determined by an observed response <code>r_obs</code> we want to fit, and the errors associated with it <code>err_resp</code>. One of the popular ways in which likelihood can be formed is using the gaussian distribution, centered around <code>r_obs</code> with variance given by <code>err_resp</code>. To make things consistent, we pass <code>r_obs</code> and <code>err_resp</code> into the final function. To make a likelihood, we just need to pass a function that can take in a response parameter and the associated error and produce a distribution. We already provide a function <code>norm_dist</code> that takes in a vector for the response and another vector/matrix for the covariance matrix of the errors. The response distribution is then constructed by:</p><pre><code class="language-julia hljs">respD = MTResponseDistribution(normal_dist, normal_dist)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Both <code>r_obs</code> and <code>err_resp</code> have the same type, eg. <code>MTResponse</code>. </p></div></div><h2 id="Inference"><a class="docs-heading-anchor" href="#Inference">Inference</a><a id="Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Inference" title="Permalink"></a></h2><p>We now have all the ingredients to perform inversion, except the sampler. This <a href="https://turing.ml/dev/docs/using-turing/sampler-viz">page</a> provides a brief review of samplers <code>Turing.jl</code> provides. The number of posterior points to be sampled <code>n_samples</code>, the algorithm <code>mcmc_alg</code> and the distributions are brought together by <code>mcmc_cache</code>.</p><pre><code class="language-julia hljs">mcmc_alg = NUTS();
n_samples = 40;
mcache = mcmc_cache(modelD, respD, n_samples, mcmc_alg);</code></pre><p>The posterior samples are then sampled by simply calling:</p><pre><code class="language-julia hljs">mcmc_chain = stochastic_inverse(r_obs, err_resp, ω, mcache)</code></pre><h2 id="Copy-Pasteable-code"><a class="docs-heading-anchor" href="#Copy-Pasteable-code">Copy-Pasteable code</a><a id="Copy-Pasteable-code-1"></a><a class="docs-heading-anchor-permalink" href="#Copy-Pasteable-code" title="Permalink"></a></h2><pre><code class="language-julia hljs">using MT
using Distributions
using Turing
using LinearAlgebra


m_test = MTModel(log10.([100., 10., 1000.]), [1e3, 1e3]);
f = 10 .^ range(-4, stop = 1, length = 25);
ω = vec(2π .* f);

r_obs = forward(m_test, ω);

err_phi = asin(0.01) * 180/π .* ones(length(ω));
err_appres = 0.02 * r_obs.ρₐ;
err_resp = MTResponse(err_appres, err_phi);

r_obs.ρₐ .= r_obs.ρₐ .+ err_appres;
r_obs.ϕ .= r_obs.ϕ .+ err_phi;

respD = MTResponseDistribution(normal_dist, normal_dist);

z = 10 .^collect(range(1, stop = 4, length = 100));
h = diff(z);


modelD = MTModelDistribution(
    Product(
    [Uniform(-1., 5.) for i in eachindex(z)]
    ),
    vec(h)
);


n_samples = 50;
mcache = mcmc_cache(modelD, respD, 50, NUTS());

mcmc_chain = stochastic_inverse(r_obs, err_resp, ω, mcache)</code></pre><p>The obtained <code>mcmc_chain</code> contains the distributions that can be saved using <a href="https://github.com/JuliaIO/JLD2.jl">JLD2.jl</a>.</p><pre><code class="language-julia hljs">using JLD2
JLD2.@save &quot;file_path.jld2&quot; mcmc_chains</code></pre><p><strong>Note</strong>: </p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The returned chains will be sampled in the distribution specified by <code>modelD</code>. In the presented case, it will have values <span>$\in [-1, 5]$</span> and we can get the values by <code>10. ^ value</code>.</p></div></div><p>The list of models can then be obtained from chains using</p><pre><code class="nohighlight hljs">model_list = get_model_list(mcmc_chains, modelD)</code></pre><p>We can then easily check the fit of the response curves</p><pre><code class="nohighlight hljs">plt_resps = prepare_plot(r_obs, ω, alpha = 0.);
resp_models = forward(model_list[1], ω);

for i in 1:(length(model_list) &gt; 50 ? 50 : length(model_list))
   forward!(resp_models, model_list[i], ω);
   prepare_plot!(resp_models, ω, alpha = 0.4); 
end

prepare_plot!(r_obs, ω, d_err = err_resp, markersize = 3, color = :orange);
plot_response(plt_resps)</code></pre><p>The posterior distribution can then be obtained as:</p><pre><code class="language-julia hljs">pre_img = pre_image(m_dist, mt_chain);
kde_img = get_kde_image(pre_img..., false, xscale = :identity, yscale = :identity, yflip = true)</code></pre><p>We can also obtain the mean and 1 std deviation bounds as:</p><pre><code class="language-julia hljs">mean_std_plt_lin = get_mean_std_image(pre_img..., yscale = :identity)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="interface_guide.html">« interface guide</a><a class="docs-footer-nextpage" href="tutorials/fixed_discretization.html">MCMC with fixed discretization »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.10.1 on <span class="colophon-date" title="Wednesday 16 April 2025 21:03">Wednesday 16 April 2025</span>. Using Julia version 1.10.9.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
